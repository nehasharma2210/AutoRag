#!/usr/bin/env python3
"""
Simple deployment test script
"""

import requests
import time
import sys

def test_backend(base_url="http://localhost:3001"):
    """Test backend health"""
    try:
        response = requests.get(f"{base_url}/api/health", timeout=10)
        if response.status_code == 200:
            print("âœ… Backend is healthy")
            return True
        else:
            print(f"âŒ Backend health check failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Backend connection failed: {e}")
        return False

def test_llm_api(base_url="http://localhost:8000"):
    """Test LLM API health"""
    try:
        response = requests.get(f"{base_url}/health", timeout=10)
        if response.status_code == 200:
            print("âœ… LLM API is healthy")
            return True
        else:
            print(f"âŒ LLM API health check failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ LLM API connection failed: {e}")
        return False

def test_query(base_url="http://localhost:8000"):
    """Test a simple query"""
    try:
        payload = {
            "query": "What is machine learning?",
            "threshold": 0.5,
            "max_results": 3,
            "use_healing": True
        }
        response = requests.post(f"{base_url}/query", json=payload, timeout=30)
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Query test successful: {data.get('answer', 'No answer')[:100]}...")
            return True
        else:
            print(f"âŒ Query test failed: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Query test failed: {e}")
        return False

def main():
    print("ğŸ§ª AutoRAG Deployment Test")
    print("=" * 40)
    
    # Wait a bit for services to start
    print("â³ Waiting for services to start...")
    time.sleep(10)
    
    # Test backend
    backend_ok = test_backend()
    
    # Test LLM API
    llm_ok = test_llm_api()
    
    if backend_ok and llm_ok:
        print("\nğŸ¯ Testing query functionality...")
        query_ok = test_query()
        
        if query_ok:
            print("\nğŸ‰ All tests passed! Deployment is successful.")
        else:
            print("\nâš ï¸ Basic services are running but query functionality has issues.")
    else:
        print("\nâŒ Some services are not responding properly.")
        sys.exit(1)

if __name__ == "__main__":
    main()